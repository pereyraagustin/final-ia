{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-YF7Q-JW00os"
   },
   "source": [
    "# Trabajo práctico final para la Materia Inteligencia Artificial - IUA - 2021\n",
    "\n",
    "## Este trabajo tiene como finalidad aplicar los siguientes conceptos:\n",
    "\n",
    "*   Regresión\n",
    "*   Redes Neuronales\n",
    "*   Árboles de Decisión\n",
    "*   Modelos de Ensamble\n",
    "*   Suport Vector Machines\n",
    "*   Validación de Modelos\n",
    "\n",
    "\n",
    "El trabajo se va a seguir realizando en grupos igual o menores de 3 participantes.\n",
    "\n",
    "La fecha de entrega del mismo es 25 de noviembre del 2021.\n",
    "\n",
    "Tener en cuenta que **este trabajo no reemplaza al examen final**, sino que va a *representar el 50% de la misma* (equivalente a la parte práctica del final).\n",
    "\n",
    "**La nota de este trabajo se puede guardar hasta febrero del 2022.** Para finales posteriores a esa fecha, van a tener que realizar la parte práctica correspondiente en ese momento.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "oexyLXnV0v_L"
   },
   "outputs": [],
   "source": [
    "# Importación de las librerías necesarias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Puede que nos sirvan también\n",
    "import matplotlib as mpl\n",
    "mpl.get_cachedir()\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "# import sklearn as skl\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error, classification_report, mean_squared_log_error\n",
    "from sklearn import ensemble\n",
    "from sklearn import svm\n",
    "from sklearn import neural_network\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor as DT\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gWU-Dgs0G86p"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2202/1941531112.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://raw.githubusercontent.com/melicaffa/practicos/main/Walmart_Store_sales.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('https://raw.githubusercontent.com/melicaffa/practicos/main/Walmart_Store_sales.csv')\n",
    "dataset['Date'] = pd.to_datetime(dataset['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yuxS8--wks_t"
   },
   "source": [
    "## Descripción del Dataset\n",
    "\n",
    "Este dataset presenta datos históricos de ventas de tiendas Walmart de Estados Unidos entre el periodo comprendido desde 05/2/2010 hasta 01/11/2012. Presenta las siguientes columnas:\n",
    "\n",
    "**Store** - nro de tienda\n",
    "\n",
    "**Date** - fecha\n",
    "\n",
    "**Weekly_Sales** - ventas semanales en determinada tienda\n",
    "\n",
    "**Holiday_Flag** - si dicha semana presenta alguna festividad: 1 – hay una festividad, 0 – no hay festividad\n",
    "\n",
    "**Temperature** - temperatura en grados fahrenheit\n",
    "\n",
    "**Fuel_Price** - costo del combustible en la región\n",
    "\n",
    "**CPI** – Índice de precios al consumidor predominante\n",
    "\n",
    "**Unemployment** - Tasa de desempleo predominante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "TzYq2ceBllvg",
    "outputId": "a6b12c72-c043-4449-8dac-cc38ecb16a7a"
   },
   "outputs": [],
   "source": [
    "# Visualizamos las columnas y sus respectivos tipos de datos\n",
    "pd.DataFrame(dataset.dtypes, columns=['Type']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "OQxDL43EJx7w",
    "outputId": "2c6661ea-061a-414c-f182-2803b6720a1e"
   },
   "outputs": [],
   "source": [
    "# Visualizamos las estadísticas de las columnas\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vowZGI7bmgnN",
    "outputId": "0088c6c3-c4a5-44ef-a5d3-bcbcb74447c2"
   },
   "outputs": [],
   "source": [
    "# Creamos más variables con los siguientes datos\n",
    "dataset['Day'] = dataset['Date'].dt.day\n",
    "dataset['Week'] = dataset['Date'].dt.week\n",
    "dataset['Month'] = dataset['Date'].dt.month\n",
    "dataset['Year'] = dataset['Date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "8lVy_oDaPh7O",
    "outputId": "4213af3f-63e0-4cfc-c6c6-8afe9a71eb94"
   },
   "outputs": [],
   "source": [
    "# Muestro 10 filas random para ver cómo son los datos\n",
    "dataset.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMuvN9PNpEnY"
   },
   "source": [
    "## Dividimos el dataset en Test y Train\n",
    "### También separamos nuestra variable objetivo que van a ser Weekly_Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kbbdzp2yovCH"
   },
   "outputs": [],
   "source": [
    "# Separamos Weekly_sales\n",
    "dataset['Date'] = dataset['Date'].apply(lambda x : x.toordinal()) # Corrección necesaria para poder hacer regresión lineal sobre fechas como números, no datetime. Ver https://stackoverflow.com/questions/69186900/invalid-type-promotion-in-linear-regression-using-scikitlearn\n",
    "y = dataset['Weekly_Sales']\n",
    "X = dataset.iloc[:, dataset.columns != 'Weekly_Sales']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "calR0hBRqFYb",
    "outputId": "75ec703b-793f-4312-9e5f-b41f4ec4ff47"
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "C5ruFQwqnopt",
    "outputId": "227423a7-03c2-4e05-d3e6-20e805d796db"
   },
   "outputs": [],
   "source": [
    "# Promedio de Ventas Semanales según semana del año\n",
    "f, ax = plt.subplots(figsize=(20, 6))\n",
    "fig = sns.boxplot(x='Week', y=\"Weekly_Sales\", data=dataset, showfliers=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D5ofeixlq1nc"
   },
   "source": [
    "Las ventas semanales son bastantes similares a lo largo del año. \n",
    "Tienen poca varianza y sólo vemos grandes aumentos en 2 semanas especiales: **thanksgiving y Navidad**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "tT6F-UQGn85k",
    "outputId": "16a78d27-e3fb-4a75-f7b5-ee8a61eecdd2"
   },
   "outputs": [],
   "source": [
    "# Promedio de Ventas Semanales según Store\n",
    "f, ax = plt.subplots(figsize=(20, 6))\n",
    "fig = sns.boxplot(x='Store', y=\"Weekly_Sales\", data=dataset, showfliers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "wG-UWBo40-3A",
    "outputId": "4d08dc74-38fd-483e-8da7-209943caca6f"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "sns.scatterplot(x=dataset.Temperature, y=dataset.Weekly_Sales, s=80);\n",
    "sns.set_style('darkgrid')\n",
    "plt.xlabel('Temperatura', fontsize=18)\n",
    "plt.ylabel('Ventas', fontsize=18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "pCy8E74noe72",
    "outputId": "1bd20a49-70f6-4379-b087-01fc0ea718a7"
   },
   "outputs": [],
   "source": [
    "print('Holiday_Flag vs Weekly_Sales')\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "#En Azul son los datos de Entrenamiento y en naranja los de Test\n",
    "sns.stripplot(y=y_train,x=X_train['Holiday_Flag'])\n",
    "plt.subplot(1,2,2)\n",
    "sns.violinplot(y=y_test,x=X_test['Holiday_Flag']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3v00FDdTqcm4"
   },
   "source": [
    "**Podemos ver que los datos de test y train se comportan de manera similar y son congruentes entre si.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VYGfVufQr1gA"
   },
   "source": [
    "## Aplicación de Modelos de Aprendizaje Automático Supervisado\n",
    "\n",
    "Se propone implementar diferentes modelos de regresión **para el dataset seleccionado**, utilizando la librería Scikit-Learn (o la que consideren apropiada):\n",
    "\n",
    "1. Support Vector Machines (SVM), probando distintos kernels para la regresión.\n",
    "2. Árboles de Decisión. \n",
    "3. Random Forest.\n",
    "4. Red neuronal.\n",
    "\n",
    "En todos los casos verificar si los datos necesitan ser normalizados o no, y si tienen que utilizar todas las columnas o es necesario tomar sólo una que sea más representativa.\n",
    "\n",
    "De estos tres modelos, cuál creen que es el más adecuado para nuestro caso de aplicación? Qué métricas utilizan para la elección?\n",
    "\n",
    "**Elegir el modelo que consideren que mejor aplica a nuestro problema.**\n",
    "\n",
    "Finalmente, para el modelo selecionado:\n",
    "\n",
    "- Utilizar el método *Grid Search*, con *cross-validation* para profundizar en la búsqueda y selección de hiperparámetros.\n",
    "- Calcular métricas sobre el conjunto de entrenamiento y de evaluación para los mejores parámetros obtenidos:\n",
    "   + Mean Absolute Error (MAE): Esta métrica de regresión es el valor medio de la diferencia absoluta entre el valor real y el valor predicho.\n",
    "   + Mean Squared Error (MSE) : El error cuadrático medio (ECM) calcula el valor medio de la diferencia al cuadrado entre el valor real y el predicho para todos los puntos de datos. Todos los valores relacionados se elevan a la segunda potencia, por lo tanto, todos los valores negativos no se compensan con los positivos. \n",
    "   + R2 Score:  Esta métrica calcula cuán bien se adapta el modelo de regresión a los datos observados. \n",
    "     \n",
    "- ¿Cuál consideran la métrica más apropiada para utilizar en nuestros modelos? ¿Por qué?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zZd8t-auvUTE"
   },
   "source": [
    "### 1. SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASJucAfa8qL_"
   },
   "source": [
    "SVM necesita que los datos se normalicen (ver https://scikit-learn.org/stable/modules/svm.html#tips-on-practical-use)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oi76ldE-9BiG"
   },
   "source": [
    "#### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T0Bp_T7yxSP3",
    "outputId": "2724683d-a0de-4ed8-aa36-cd87a20dd282"
   },
   "outputs": [],
   "source": [
    "## Dudas: ¿Podemos no probar sin normalizar ya que la doc dice que hace falta normalizar?\n",
    "### ¿Sería correcto decir que las SVR son malas para la predicción de este problema porque, al estar tan juntos entre sí las potenciales ventas semanales, resulta muy difícil para el modelo\n",
    "### encontrar hiperplanos que los separen?\n",
    "### ¿Sólo probamos con diferentes kernels pero el resto de hiperparámetros iguales? ¿O también probamos combinaciones de hiperparámetros? No cambiamos hiperparámetros\n",
    "### ¿Cómo sé si debería tomar una sola columna o várias? ¿Probando o en función de algo indicado por el algoritmo? Tenemos que probar y justificar... Probar \n",
    "### Probar también si el rendimiento del modelo cambia con datos normalizados y no normalizados (no debería hacer falta para SVR, justificar con link)\n",
    "# Kernels de SVR a probar\n",
    "## Usamos MSLE porque es útil para valores a predecir que crecen exponencialmente, como ventas -> https://scikit-learn.org/stable/modules/model_evaluation.html#mean-squared-logarithmic-error\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid'] # No se usa el kernel precomputed porque requiere matriz cuadrada, lo que implicaría sólo usar 11 muestras\n",
    "\n",
    "# Guardar valores originales para bucle\n",
    "X_train_original = X_train.copy(deep=True)\n",
    "X_test_original = X_test.copy(deep=True)\n",
    "\n",
    "# Listas de kernels, puntajes y columnas removidas\n",
    "# En orden. O sea, scores[0] se corresponde con la combinación left_cols[0], used_kernels[0]\n",
    "scores = []\n",
    "left_cols = []\n",
    "used_kernels = []\n",
    "\n",
    "# Probar distintas columnas y kernels\n",
    "for col in X_train_original.columns:\n",
    "  # Dejar solo una columna para probar\n",
    "  X_train = X_train.iloc[:, X_train.columns == col]\n",
    "  X_test = X_test.iloc[:, X_test.columns == col]\n",
    "  # Probamos con varios kernels\n",
    "  for kernel in kernels:\n",
    "    regr = make_pipeline(StandardScaler(), svm.SVR(kernel=kernel))\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred = regr.predict(X_test)\n",
    "    left_cols.append(col)\n",
    "    used_kernels.append(kernel)\n",
    "    scores.append(mean_squared_log_error(y_test, y_pred))\n",
    "\n",
    "  # Reiniciar train y test\n",
    "  X_train = X_train_original\n",
    "  X_test = X_test_original\n",
    "\n",
    "# Promabos los kernels usando TODAS las columnas\n",
    "for kernel in kernels:\n",
    "  regr = make_pipeline(StandardScaler(), svm.SVR(kernel=kernel))\n",
    "  regr.fit(X_train, y_train)\n",
    "  y_pred = regr.predict(X_test)\n",
    "  left_cols.append('all')\n",
    "  used_kernels.append(kernel)\n",
    "  scores.append(mean_squared_log_error(y_test, y_pred))\n",
    "\n",
    "# Obtener la mejor combinación kernel, columna para la métrica usada\n",
    "results = pd.DataFrame({'kernel': used_kernels, 'column used': left_cols, 'score': scores})\n",
    "results.iloc[results['score'].idxmin()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f93vyc-_9Kac"
   },
   "source": [
    "#### NuSVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tG_q_j11oVk8",
    "outputId": "c3ef8ca4-c98c-4766-9af3-5946d24d6ba0"
   },
   "outputs": [],
   "source": [
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid'] # No se usa el kernel precomputed porque requiere matriz cuadrada, lo que implicaría sólo usar 11 muestras\n",
    "\n",
    "# Guardar valores originales para bucle\n",
    "X_train_original = X_train.copy(deep=True)\n",
    "X_test_original = X_test.copy(deep=True)\n",
    "\n",
    "# Listas de kernels, puntajes y columnas removidas\n",
    "# En orden. O sea, scores[0] se corresponde con la combinación left_cols[0], used_kernels[0]\n",
    "scores = []\n",
    "left_cols = []\n",
    "used_kernels = []\n",
    "\n",
    "# Probar distintas columnas y kernels\n",
    "for col in X_train_original.columns:\n",
    "  # Dejar solo una columna para probar\n",
    "  X_train = X_train.iloc[:, X_train.columns == col]\n",
    "  X_test = X_test.iloc[:, X_test.columns == col]\n",
    "  # Probamos con varios kernels\n",
    "  for kernel in kernels:\n",
    "    regr = make_pipeline(StandardScaler(), svm.NuSVR(kernel=kernel))\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred = regr.predict(X_test)\n",
    "    left_cols.append(col)\n",
    "    used_kernels.append(kernel)\n",
    "    scores.append(mean_squared_log_error(y_test, y_pred))\n",
    "\n",
    "  # Reiniciar train y test\n",
    "  X_train = X_train_original\n",
    "  X_test = X_test_original\n",
    "\n",
    "# Promabos los kernels usando TODAS las columnas\n",
    "for kernel in kernels:\n",
    "  regr = make_pipeline(StandardScaler(), svm.NuSVR(kernel=kernel))\n",
    "  regr.fit(X_train, y_train)\n",
    "  y_pred = regr.predict(X_test)\n",
    "  left_cols.append('all')\n",
    "  used_kernels.append(kernel)\n",
    "  scores.append(mean_squared_log_error(y_test, y_pred))\n",
    "\n",
    "# Obtener la mejor combinación kernel, columna para la métrica usada\n",
    "results = pd.DataFrame({'kernel': used_kernels, 'column used': left_cols, 'score': scores})\n",
    "results.iloc[results['score'].idxmin()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b4ZTmSre9Nsl"
   },
   "source": [
    "#### LinearSVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Mx9Z8UHwsN3"
   },
   "source": [
    "### 2. Árboles de Decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hperTUYTxThZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_g9udbIqwsGv"
   },
   "source": [
    "### 3. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lptjA1GKxUYQ"
   },
   "outputs": [],
   "source": [
    "# Guardar valores originales para bucle\n",
    "X_train_original = X_train.copy(deep=True)\n",
    "X_test_original = X_test.copy(deep=True)\n",
    "\n",
    "# Listas de kernels, puntajes y columnas removidas\n",
    "# En orden. O sea, scores[0] se corresponde con la combinación left_cols[0], used_kernels[0]\n",
    "scores = []\n",
    "left_cols = []\n",
    "\n",
    "# Probar distintas columnas y kernels\n",
    "for col in X_train_original.columns:\n",
    "  # Dejar solo una columna para probar\n",
    "  X_train = X_train.iloc[:, X_train.columns == col]\n",
    "  X_test = X_test.iloc[:, X_test.columns == col]\n",
    "  # Probamos con varios kernels\n",
    "  for kernel in kernels:\n",
    "    regr = make_pipeline(StandardScaler(), RandomForestRegressor())\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred = regr.predict(X_test)\n",
    "    left_cols.append(col)\n",
    "    used_kernels.append(kernel)\n",
    "    scores.append(mean_squared_log_error(y_test, y_pred))\n",
    "\n",
    "  # Reiniciar train y test\n",
    "  X_train = X_train_original\n",
    "  X_test = X_test_original\n",
    "\n",
    "# Promabos los kernels usando TODAS las columnas\n",
    "for kernel in kernels:\n",
    "  regr = make_pipeline(StandardScaler(), svm.NuSVR(random_state=0))\n",
    "  regr.fit(X_train, y_train)\n",
    "  y_pred = regr.predict(X_test)\n",
    "  left_cols.append('all')\n",
    "  scores.append(mean_squared_log_error(y_test, y_pred))\n",
    "\n",
    "# Obtener la mejor combinación kernel, columna para la métrica usada\n",
    "results = pd.DataFrame({'column used': left_cols, 'score': scores})\n",
    "results.iloc[results['score'].idxmin()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hXaV_-UEwr4f"
   },
   "source": [
    "### 4. Redes Neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "buUGlz9ExVrA"
   },
   "outputs": [],
   "source": [
    "#Importo sklearn.neural_network\n",
    "#https://scikit-learn.org/stable/modules/neural_networks_supervised.html#tips-on-practical-use \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_original = X_train.copy(deep=True)\n",
    "X_test_original = X_test.copy(deep=True)\n",
    "\n",
    "#Aplicar misma escala\n",
    "scaler = StandardScaler() \n",
    "#Se realiza el fit solo en el train data\n",
    "scaler.fit(X_train_original)\n",
    "#Luego aplicamos las transformaciones tanto al train como al test\n",
    "X_train_original = scaler.transform(X_train_original) \n",
    "X_test_original = scaler.transform(X_test_original) \n",
    "\n",
    "X_train_original, X_test_original, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O6Rrhj-0w5nQ"
   },
   "source": [
    "### Elección del mejor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u9VvjVr8xWnA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WXUr7xQExDcn"
   },
   "source": [
    "### Evaluación de nuestro modelo elegido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wXXL7opHzBn9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "6Mx9Z8UHwsN3"
   ],
   "name": "TP Final IA - Grupo 1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
